{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "54b283b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import heapq\n",
    "import sklearn.feature_extraction.text\n",
    "import sklearn.model_selection\n",
    "import sklearn.tree\n",
    "import graphviz\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz/bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0d535ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_headlines():\n",
    "    headlines = []\n",
    "    with open('NEWS/clean_fake.txt', 'r') as f:\n",
    "        headlines = f.read().split('\\n')\n",
    "        n_fake = len(headlines)\n",
    "    with open('NEWS/clean_real.txt', 'r') as f:\n",
    "        headlines.extend(f.read().split('\\n'))\n",
    "        n_real = len(headlines) - n_fake\n",
    "    return headlines, n_fake, n_real\n",
    "\n",
    "def Preprocess_Data(headlines, n_fake, n_real):\n",
    "    X = vectorizer.fit_transform(headlines)\n",
    "    Y = [0 for i in range(n_fake)] + [1 for i in range(n_real)]\n",
    "    X_train, X_validate_test, Y_train, Y_validate_test = sklearn.model_selection.train_test_split(X, Y, test_size = 0.3)\n",
    "    X_validate, X_test, Y_validate, Y_test = sklearn.model_selection.train_test_split(X_validate_test, Y_validate_test, test_size = 0.5)\n",
    "    return X_train, X_validate, X_test, Y_train, Y_validate, Y_test \n",
    "\n",
    "def select_model(X_train, Y_train, X_validate, Y_validate, max_depths, criterions, k=2):\n",
    "    best_trees = []\n",
    "    for depth in max_depths:\n",
    "        for criteria in criterions:\n",
    "            tree = sklearn.tree.DecisionTreeClassifier(criterion=criteria, max_depth=depth)\n",
    "            tree.fit(X_train,Y_train)\n",
    "            Y_predict = tree.predict(X_validate, Y_validate)\n",
    "            accuracy = float(sum([1 if Y_predict[i]== Y_validate[i] else 0 for i in range(len(Y_validate))]))/float(len(Y_validate))\n",
    "            print(\"Tree max depth=%d, criterion=%s, validation_score=%f\" % (depth, criteria, accuracy))\n",
    "            heapq.heappush(best_trees, (-1*accuracy, tree))    \n",
    "    trees = []\n",
    "    for i in range(k):\n",
    "        trees.append(heapq.heappop(best_trees))\n",
    "    return trees \n",
    "    \n",
    "            \n",
    "def visualize_tree(tree, name):\n",
    "    data = sklearn.tree.export_graphviz(tree, out_file=None, feature_names=vectorizer.get_feature_names())\n",
    "    graph = graphviz.Source(data)\n",
    "    graph.render(name)\n",
    "    \n",
    "def log2(x):\n",
    "    return math.log(x)/math.log(2)\n",
    "    \n",
    "def calculate_entropy(Y):\n",
    "    count = defaultdict(int)\n",
    "    for i in range(len(Y)):\n",
    "        count[Y[i]] += 1  \n",
    "    entropy = 0\n",
    "    for y in count:\n",
    "        p = float(count[y])/len(Y)\n",
    "        entropy -= p*log2(p)\n",
    "    return entropy\n",
    "\n",
    "def splitX(X, Y, feature, split):\n",
    "    X_right, Y_right, X_left, Y_left = [[] for i in range(4)]\n",
    "    X = X.toarray()\n",
    "    for i in range(len(X)):\n",
    "        if X[i][feature] < split:\n",
    "            X_left.append(X[i])\n",
    "            Y_left.append(Y[i])\n",
    "        else:\n",
    "            X_right.append(X[i])\n",
    "            Y_right.append(Y[i])\n",
    "    return X_right, Y_right, X_left, Y_left \n",
    "\n",
    "def compute_information_gain(X, Y, feature, Split):\n",
    "    X_right, Y_right, X_left, Y_left = splitX(X, Y, feature, Split)\n",
    "    parentEntropy = calculate_entropy(Y)\n",
    "    leftEntropy = calculate_entropy(Y_left)\n",
    "    rightEntropy = calculate_entropy(Y_right)\n",
    "    IG = parentEntropy - float(len(Y_left)/len(Y))*leftEntropy - float(len(Y_right)/len(Y))*rightEntropy\n",
    "    return IG\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ab1b8e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree max depth=1, criterion=gini, validation_score=0.671429\n",
      "Tree max depth=1, criterion=entropy, validation_score=0.579592\n",
      "Tree max depth=2, criterion=gini, validation_score=0.673469\n",
      "Tree max depth=2, criterion=entropy, validation_score=0.636735\n",
      "Tree max depth=3, criterion=gini, validation_score=0.710204\n",
      "Tree max depth=3, criterion=entropy, validation_score=0.626531\n",
      "Tree max depth=4, criterion=gini, validation_score=0.714286\n",
      "Tree max depth=4, criterion=entropy, validation_score=0.712245\n"
     ]
    }
   ],
   "source": [
    "vectorizer = sklearn.feature_extraction.text.CountVectorizer()\n",
    "max_depths = range(1,5)\n",
    "criterions = ['gini', 'entropy']\n",
    "headlines, n_fake, n_real = load_headlines()\n",
    "X_train, X_validate, X_test, Y_train, Y_validate, Y_test = Preprocess_Data(headlines, n_fake, n_real)\n",
    "trees = select_model(X_train, Y_train, X_validate, Y_validate, max_depths, criterions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7c0f11f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-0.7142857142857143, DecisionTreeClassifier(max_depth=4)), (-0.7122448979591837, DecisionTreeClassifier(criterion='entropy', max_depth=4))]\n"
     ]
    }
   ],
   "source": [
    "visualize_tree(trees[0][1], 'news_tree1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b2045c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.035609234170765\n",
      "0.03690593571792811\n",
      "0.016555315061006715\n"
     ]
    }
   ],
   "source": [
    "split_words = ['hillary', 'trump', 'korea']\n",
    "for word in split_words:\n",
    "    featureIndex = vectorizer.vocabulary_.get(word)\n",
    "    print(compute_information_gain(X_train, Y_train, featureIndex, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d508256d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7026476578411406\n"
     ]
    }
   ],
   "source": [
    "Y_test_predict_t1 = trees[0][1].predict(X_test, Y_test)\n",
    "accuracy_test_t1 = sum([1 if Y_test_predict_t1[i]== Y_test[i] else 0 for i in range(len(Y_test))])/len(Y_test)\n",
    "print(accuracy_test_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "977888cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7006109979633401\n"
     ]
    }
   ],
   "source": [
    "Y_test_predict_t2 = trees[1][1].predict(X_test, Y_test)\n",
    "accuracy_test_t2 = sum([1 if Y_test_predict_t2[i]== Y_test[i] else 0 for i in range(len(Y_test))])/len(Y_test)\n",
    "print(accuracy_test_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab69d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
